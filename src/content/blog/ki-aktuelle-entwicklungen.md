---
title: "KI Aktuelle Entwicklungen 2025: Woche 48 (25.-29. November)"
description: "Die wichtigsten KI-Updates der Woche: Webdesign-Tools, Bildgenerierung, neue Assistenten und technische Durchbrüche."
author: "KI Agentur Frankfurt"
date: "2025-11-29"
category: "KI-News"
readTime: "20 min Lesezeit"
image: "/aktuelle-ki-entwicklungen.png"
---

# Wöchentlicher KI-Überblick – Kalenderwoche 48 (25.–29. Nov 2025)

Die neuesten KI-Entwicklungen der aktuellen Woche frisch aus unserer [KI Agentur](/).

## Webdesign und KI

### Figma: Neue KI-Funktionen und Sites CMS

Das Design-Tool Figma hat diese Woche seine KI-Funktionen ausgebaut. In Figma Make können jetzt experimentelle KI-Modelle genutzt werden – darunter Google Gemini 3 Pro, der neueste KI-Gigant von Google. Gleichzeitig hat Figma mit Sites CMS ein eigenes Content-Management-System als Beta gestartet, damit Designer direkt in Figma dynamische Webseiten und Blogs erstellen können. Außerdem gibt es Verbesserungen für Design-Systeme wie erweiterte Collections für Multi-Brand-Designs. Kurz: Figma verknüpft immer stärker Design-Workflows mit KI, um Prototyping und Webdesign zu beschleunigen.

### Wix: Neue KI-Design-Plattform Wixel

Auch der Webbaukasten Wix setzt voll auf KI. Bereits zuvor hatte Wix einen AI Site Builder vorgestellt, der per Chat-Dialog komplette Websites samt Layout, Text und Bildern generiert. Nun geht Wix noch weiter: Mit Wixel hat das Unternehmen eine eigene KI-Design-Plattform gestartet. Wixel soll professionelle Grafikbearbeitung für alle zugänglich machen. Nutzer können z.B. ein Produktfoto hochladen und den Hintergrund oder die Umgebung per KI austauschen, Farben anpassen oder Texte einfügen – alles in wenigen Minuten. Im Hintergrund wählt Wixel automatisch die besten Modelle für jede Aufgabe aus, u.a. OpenAIs neueste Bild-KI. Das Ziel: Design auf Profi-Niveau, ohne dass man selbst Experte sein muss.

### Adobe: Firefly Image Model 5 und Audio-KI

Der Kreativsoftware-Riese Adobe hat auf seiner MAX-Konferenz Ende Oktober weitreichende KI-Neuerungen angekündigt, die jetzt ausgerollt werden. Adobe Firefly, Adobes generative Bild-KI, wurde auf Image Model 5 aktualisiert – dieser erzeugt Bilder in höherer 4-Megapixel-Auflösung (ca. 2K) und erlaubt erstmals ebenenbasiertes Bearbeiten. In der Praxis heißt das: Firefly kann Objekte im Bild erkennen, verschieben oder ersetzen, ohne Qualitätseinbußen.

Zudem hat Adobe KI-Audiofunktionen eingeführt: Generate Soundtrack schlägt automatisch Hintergrundmusik für Videos vor, und Generate Speech erzeugt Sprachkommentare in 15 Sprachen (auch mit Emotionseffekten). Selbst ein KI-gestützter Video-Editor im Browser ist in Arbeit. Darüber hinaus bekommen Programme wie Photoshop und Express eingebaute KI-Assistenten, die bei Aufgaben helfen oder Einstellungen automatisch vornehmen. Adobe zeigt damit, dass KI künftig ein Kernbestandteil der Kreativ-Tools ist.

### Canva: Editierbare generative Designs

Auch Canva – die beliebte Online-Design-Plattform – setzt verstärkt auf KI. Kürzlich hat Canva ein eigenes generatives Design-Modell vorgestellt, das nicht nur flache Bilder erzeugt, sondern voll editierbare Entwürfe mit einzelnen Ebenen und Objekten. Damit können Nutzer ein Design per Textprompt erstellen und anschließend jedes Element (Text, Bild, Grafik) nach Belieben bearbeiten.

Zusätzlich hat Canva seinen KI-Assistenten ausgebaut: In der Oberfläche lässt sich nun überall ein Chatbot (@Canva AI) ansprechen, um z.B. Textvorschläge oder Bildideen zu erhalten. Neu sind auch Funktionen wie automatisch generierte 3D-Objekte, die sich ins Design einfügen lassen, sowie KI-gestützte Formular- und E-Mail-Designs. Canva zeigt damit, wie KI den Kreativprozess vereinfacht – von Social-Media-Posts bis hin zu Präsentationen und Marketingmaterial.

## Bildgenerierung (Text-zu-Bild)

### Google & Adobe – Neues Bildmodell Nano Banana Pro

Ein Highlight dieser Woche ist Googles neues Bildgenerierungs-Modell „Nano Banana Pro", das als Teil von Gemini 3 veröffentlicht wurde. Diese KI erzeugt gestochen scharfe Bilder bis 4K-Auflösung und kann Texte in Bildern fehlerfrei darstellen. Adobe hat das Modell sofort in seine Tools eingebunden: In Photoshop und der Firefly-Webapp können Nutzer jetzt Nano Banana Pro direkt nutzen.

Zum Ausprobieren hat Adobe sogar bis Anfang Dezember unbegrenzte KI-Generierungen für zahlende Kunden freigeschaltet – ein Zeichen dafür, wie wichtig dieses Update ist. Nano Banana Pro bietet auch mehr Steuerungsmöglichkeiten („Kamera"-Parameter für Perspektive usw.) und kennzeichnet erstellte Bilder automatisch mit unsichtbaren Wasserzeichen. Damit setzt Google ein Ausrufezeichen in Sachen Bild-KI und Adobe sorgt dafür, dass Kreative sofort davon profitieren.

### Midjourney: Profile und Style Creator

Die bekannte KI-Bildplattform Midjourney hat ihre Tools diese Woche um praktische Features erweitert. Neu ist Midjourney Profiles – jeder Nutzer erhält nun ein öffentliches Profil auf midjourney.com, um dort die eigenen KI-Bilder zu präsentieren. Das fördert den Community-Aspekt und ermöglicht es, Inspiration bei anderen zu finden.

Noch spannender ist der Start des Style Creator (Beta) am 21. November: Statt mühsam einen Prompt zu perfektionieren, können Anwender jetzt einen eigenen Bildstil trainieren. Man wählt Beispielbilder oder gibt Referenzen vor, und Midjourney erstellt daraus einen Style-Parameter, mit dem man konsistente Bildserien in diesem Look erzeugen kann. Dieser Style Creator nimmt einem das Rätselraten bei Prompt-Beschreibungen ab – die KI lernt den gewünschten Stil und reproduziert ihn zuverlässig. Für kreative Köpfe bedeutet das: Lieblingsästhetiken lassen sich in Zukunft per Klick anwenden, von Comic-Stil über Fotorealismus bis hin zu abstrakten Kunststilen.

### Recraft: Ebenen-Effekte und neue Modelle

Abseits der großen Player tut sich auch bei unabhängigen KI-Design-Tools einiges. Die Plattform Recraft, die auf KI-generierte Grafiken für Designer spezialisiert ist, hat in dieser Woche zwei bemerkenswerte Updates erhalten. Erstens wurde Googles Nano Banana Pro als neues Bildmodell integriert, sodass Recraft-Nutzer Zugriff auf die hohe Qualität dieses Modells haben.

Zweitens hat Recraft sein Editor-Werkzeug erweitert: Ab sofort gibt es Ebenen-Effekte wie Schatten, Konturen (Stroke) und Unschärfe, die man direkt auf generierte oder importierte Bildelemente anwenden kann. Damit lassen sich KI-Grafiken feinschleifend bearbeiten – z.B. ein leichter Schatten für mehr Tiefe oder ein Glow-Effekt für Highlights. Diese Funktionen bringen Recraft näher an klassische Designprogramme heran und geben Nutzern „unprecedented control" über KI-Bilder.

## KI-Tools und Assistenten

### ChatGPT mit Gruppenchat

OpenAI hat seinen KI-Assistenten ChatGPT in einen kleinen „Teamplayer" verwandelt. Seit dieser Woche können Nutzer Gruppen-Chats eröffnen, in denen bis zu 20 Personen gemeinsam mit einem ChatGPT-Bot kommunizieren. Das Feature wurde zunächst getestet und nun weltweit freigeschaltet.

In so einem Chat kann man zum Beispiel mit Freunden eine Reise planen oder im Team an einem Dokument arbeiten, während ChatGPT live mithilft – etwa Infos nachschlagen, Zusammenfassungen liefern oder Ideen vorschlagen. Wichtig: Jeder Teilnehmer behält seine persönlichen Voreinstellungen, und ChatGPT antwortet nur, wenn es direkt angesprochen oder „@ChatGPT" getaggt wird. OpenAI sieht darin den Startschuss, ChatGPT von einem reinen 1-zu-1-Assistenten zu einer kollaborativen Plattform zu entwickeln.

### OpenAI GPT-5.1 und Codex-Max

Neben dem Gruppenchat hat OpenAI vor Kurzem weitere Verbesserungen ausgerollt. Das Sprachmodell hinter ChatGPT wurde auf GPT‑5.1 angehoben – mit zwei Varianten: **Instant** (schnelle, dialogfreudige Antworten) und **Thinking** (gründlicheres, schrittweises Vorgehen für komplexe Aufgaben). GPT‑5.1 reagiert spürbar natürlicher und lässt sich vom Nutzer in Tonfall und Stil stärker anpassen.

Ebenfalls wichtig für Entwickler: OpenAI hat eine neue Version seines Codierassistenten vorgestellt, **GPT‑5.1-Codex-Max**, der speziell auf Softwareentwicklung ausgelegt ist. Dieses Modell kann umfangreiche Coding-Probleme lösen, über Stunden an großen Projekten arbeiten und in mehreren Dateien gleichzeitig Code verstehen und verbessern. Mit GPT-5.1 Codex-Max will OpenAI die Messlatte für KI-Codetools höher legen – es soll weniger „halluzinieren" (also falschen Code schreiben) und komplexe Programmieraufgaben nahezu fehlerfrei bewältigen.

### xAI Grok 4.1

Nicht nur OpenAI, auch Elon Musks Startup xAI hat ein Upgrade herausgebracht. Deren Chatbot Grok liegt jetzt in Version 4.1 vor. Grok 4.1 zielt darauf ab, aus dem vieldiskutierten „frechen" Chatbot einen zuverlässigen KI-Gefährten zu machen. Laut xAI ist das neue Modell deutlich schneller und hat eine geringere Halluzinationsrate, gibt also weniger unsinnige Antworten.

Gleichzeitig wurde Groks „Persönlichkeit" weiterentwickelt, um kreativer und einfühlsamer zu reagieren – Grok 4.1 soll Nutzer besser emotional verstehen können und natürlicher plaudern. Ein besonderes Feature ist der **„Thinking Mode"**: Ähnlich wie ChatGPTs Denkmodus kann Grok dabei schwierige Fragen Schritt für Schritt durchdenken (z.B. Matheaufgaben oder Code-Probleme), was präzisere Lösungen liefern soll. Seit dem 19. November ist Grok 4.1 für alle Nutzer verfügbar.

### Weitere neue Helfer

Überall entstehen aktuell neue spezialisierte KI-Tools. Ein Beispiel: **Google Antigravity**, diese Woche vorgestellt, ist eine KI-gestützte Entwicklungsumgebung für Programmierer. Hier arbeiten mehrere KI-Agenten zusammen, um Code zu schreiben, Tests durchzuführen oder sogar eigenständig im Browser Informationen zu suchen – alles integriert in einer IDE (Entwicklungsoberfläche).

Ein weiteres Beispiel ist **Perplexity AI**, dessen neuer Comet-Browser für Android diese Woche Schlagzeilen machte. Comet ist ein smarter mobiler Webbrowser, der Webseiten automatisch zusammenfasst, per Chat Fragen zu offenen Tabs beantwortet und sogar Aufgaben wie Buchungen im Hintergrund erledigen kann.

## Technische Neuerungen und Forschung

### Google Gemini 3

In der KI-Forschung markiert Google einen Meilenstein mit Gemini 3, vorgestellt am 18. November. Dieses Modell wird als Googles bisher „intelligentestes" KI-Modell beschrieben. Gemini 3 kombiniert alle Fortschritte der Vorgänger: Es versteht komplexe Zusammenhänge besser, kann multimodal arbeiten (also mit Text, Bildern und Code umgehen) und zeigt herausragende Fähigkeiten im logischen Schlussfolgern.

In internen Tests übertrifft Gemini 3 Pro die vorherigen Google-Modelle deutlich – etwa bei Verständnisfragen, Programmieraufgaben und beim Lösen kniffliger Probleme. Ein spezieller „Deep Think"-Modus soll bald für zahlende Nutzer kommen und die Intelligenz bei sehr schwierigen Aufgaben nochmals steigern. Wichtig auch: Google hat Gemini 3 direkt breit verfügbar gemacht – es steckt hinter dem neuen Gemini AI Assistant (einer eigenständigen App), ist über die Google Cloud (Vertex AI) nutzbar und treibt sogar neue Entwickler-Tools wie das oben erwähnte Antigravity an.

### Anthropic Claude Opus 4.5

Auch Anthropic – das KI-Startup hinter Claude – hat diese Woche sein neuestes Sprachmodell vorgestellt. Claude Opus 4.5 (Codename Opus) ist am 24. Nov erschienen und hat besonders in Sachen Programmierung und Agenten große Sprünge gemacht. Laut Anthropic ist Opus 4.5 derzeit weltweit führend bei Coding-Benchmarks; es ist das erste KI-Modell überhaupt, das über 80% auf dem schwierigen SWE-Bench (Software-Engineering-Test) erreicht.

Das heißt, Claude kann jetzt Code schreiben und verstehen auf einem Niveau, das menschliche Top-Programmierer schlägt. Gleichzeitig wurden „Agentic"-Fähigkeiten verbessert: Opus 4.5 kann eigenständiger Tools nutzen und mehrere Schritte planen – etwa mehrere KI-Unteragenten koordinieren, um komplexe Aufgaben zu lösen.

Für Anwender bemerkbar sind auch praktische Updates: Anthropic hat Claude für Chrome (eine Browser-Erweiterung) und Claude für Excel veröffentlicht, die nun allen Pro-Nutzern bzw. Enterprise-Kunden offenstehen. Zudem hat Claude jetzt ein ultralanges Gedächtnis und beherrscht „endlose Chats" – in langen Gesprächen komprimiert Claude automatisch ältere Kontexte, sodass man ohne Reset weiterschreiben kann.

### Meta SAM 3 & SAM 3D

Von Meta (Facebook) kommt ein Durchbruch im Bereich Computer Vision. Am 19. Nov hat Meta SAM 3 und SAM 3D vorgestellt, neueste Versionen des Segment-Anything-Modells. SAM 3 kann nun Objekte in Bildern und Videos nicht nur mit Klick, sondern auch per Textbeschreibung segmentieren und verfolgen. Beispiel: Man tippt „roter Baseballcap" ein, und SAM 3 markiert in einem Video alle roten Kappen – etwas, das frühere Modelle mangels Sprach-Verständnis nicht hinbekamen.

SAM 3D geht noch einen Schritt weiter: Dieses offene Modell kann aus einem einzigen Foto ein 3D-Modell des abgebildeten Objekts oder sogar einer Person erzeugen. Dabei werden zwei KI-Modelle genutzt – eines für allgemeine Objekte/Umgebungen, eines speziell für menschliche Körper. Die erzeugten 3D-Objekte sind so gut, dass Meta sie direkt einsetzt: Auf Facebook Marketplace gibt es nun eine „Im Raum ansehen"-Funktion, bei der ein einfaches Produktfoto von SAM 3D in ein 3D-Modell umgewandelt wird. Nutzer können z.B. eine Lampe virtuell in ihrem Wohnzimmer platzieren, um Größe und Stil vor dem Kauf besser einzuschätzen.

### DeepMind WeatherNext 2

Im Schatten der großen Modellankündigungen gab es auch in der angewandten Forschung spannende News. DeepMind (Googles KI-Tochter) hat ein KI-Modell namens WeatherNext 2 präsentiert, das die Wettervorhersage revolutionieren könnte. WeatherNext 2 erstellt Stundenprognosen bis zu 15 Tage im Voraus – und das achtmal schneller als herkömmliche meteorologische Modelle. Insbesondere bei Unwettern und Stürmen soll das System deutlich bessere Trefferquoten haben.

Möglich wird dies durch eine Kombination aus DeepMinds KI-Expertise und klassischen physikalischen Wetterdaten. WeatherNext 2 kann enorme Mengen historischer Wetterdaten verarbeiten und Muster erkennen, wo traditionelle Modelle an Rechen- und Zeitgrenzen stoßen. Für Meteorologen heißt das: präzisere und schnellere Vorhersagen, die z.B. bei Extremwetter Warnzeiten verlängern könnten.

## Fazit

In dieser Woche hat sich im KI-Bereich enorm viel getan – von praktischen Produkt-Updates bis zu technischen Durchbrüchen. Design-Plattformen wie Figma, Wix, Adobe und Canva statten Kreative mit immer smarteren KI-Werkzeugen aus, während bei den Bildgeneratoren ein regelrechtes Wettrüsten herrscht (Google vs. Adobe vs. Midjourney etc.).

Gleichzeitig wachsen KI-Assistenten wie ChatGPT oder Claude über sich hinaus und lernen zusammenzuarbeiten oder programmieren. Und in den Forschungslaboren entstehen Modelle, die die Grenzen des Möglichen verschieben – sei es bei multimodaler Intelligenz (Gemini 3), 3D-Verständnis (SAM 3D) oder Wetterprognosen.

Alles in allem sieht man: die KI-Welt bleibt hochdynamisch. Was letzte Woche noch neu war, ist diese Woche schon im Einsatz – und erleichtert Webdesign, Kreativarbeit, Programmierung und vieles mehr. Es bleibt spannend, wohin uns diese rasante Entwicklung führt – aber Kalenderwoche 48 hat jedenfalls gezeigt, dass KI weiterhin auf der Überholspur ist.

---

*Hinweis: Diese Zusammenfassung basiert auf öffentlich zugänglichen Quellen, Unternehmensankündigungen und Community-Diskussionen der Woche 25.-29. November 2025.*
